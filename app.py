# ==============================================
# üí¨ Chatbot Regulatorio Interno
# Versi√≥n completa (Excel + OpenAI + Streamlit)
# ==============================================

import os
import openai
import pandas as pd
import nltk
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords
import streamlit as st

# ==============================================
# 1Ô∏è‚É£ CONFIGURACI√ìN INICIAL
# ==============================================

# Usa tu clave de OpenAI (debe estar guardada en una variable de entorno)
openai.api_key = os.getenv("OPENAI_API_KEY")

# Descargar stopwords si no est√°n instaladas
nltk.download("stopwords", quiet=True)
stop_words = stopwords.words("spanish")

# ==============================================
# 2Ô∏è‚É£ CARGAR EL DATASET (Excel)
# ==============================================
@st.cache_data(show_spinner=False)
def cargar_datos():
    try:
        df = pd.read_excel("conversaciones_revisando.xlsx")
        df.columns = df.columns.str.strip().str.capitalize()
        df["Role"] = df["Role"].str.lower()
        consultas = df[df["Role"] == "user"]["Content"].fillna("").tolist()
        respuestas = df[df["Role"] == "assistant"]["Content"].fillna("").tolist()
        pares = list(zip(consultas, respuestas))
        return pares
    except Exception as e:
        st.error(f"‚ö†Ô∏è Error al cargar el archivo Excel: {e}")
        return []

pares = cargar_datos()
if not pares:
    st.stop()

st.sidebar.success(f"üìÑ Dataset cargado con {len(pares)} pares de consulta-respuesta.")

# ==============================================
# 3Ô∏è‚É£ VECTORIZACI√ìN DE TEXTO
# ==============================================
@st.cache_resource(show_spinner=False)
def crear_vectorizador():
    vectorizador = TfidfVectorizer(stop_words=stop_words)
    X = vectorizador.fit_transform([c for c, _ in pares])
    return vectorizador, X

vectorizador, X = crear_vectorizador()

# ==============================================
# 4Ô∏è‚É£ FUNCI√ìN PRINCIPAL DE RESPUESTA
# ==============================================
def responder_chatbot(pregunta, top_k=3):
    # Buscar las consultas m√°s parecidas
    vector_pregunta = vectorizador.transform([pregunta])
    similitudes = cosine_similarity(vector_pregunta, X).flatten()
    indices_top = similitudes.argsort()[::-1][:top_k]
    
    # Crear el contexto
    contexto = "\n\n".join(
        [f"Consulta: {pares[i][0]}\nRespuesta: {pares[i][1]}" for i in indices_top]
    )

    # Generar el prompt
    prompt = f"""
Eres un asistente experto en regulaci√≥n cosm√©tica.
Responde de forma clara, t√©cnica y concisa a la siguiente consulta,
bas√°ndote en el contexto hist√≥rico del equipo t√©cnico.

Contexto relevante:
{contexto}

Nueva consulta:
{pregunta}

Si no hay informaci√≥n suficiente, indica que no dispones de datos internos al respecto.
"""

    # Llamada a la API de OpenAI
    try:
        respuesta = openai.chat.completions.create(
            model="gpt-4o",
            temperature=0,  # garantiza respuestas consistentes
            messages=[{"role": "user", "content": prompt}]
        )
        return respuesta.choices[0].message.content.strip()
    except Exception as e:
        return f"‚ö†Ô∏è Error al generar la respuesta: {e}"

# ==============================================
# 5Ô∏è‚É£ INTERFAZ STREAMLIT
# ==============================================
st.title("üí¨ Chatbot Regulatorio Interno")
st.write("Escribe tu consulta relacionada con normativa cosm√©tica o procedimientos t√©cnicos.")

pregunta = st.text_area("üß¥ Tu consulta:")
if st.button("Enviar"):
    if pregunta.strip():
        with st.spinner("Analizando consulta..."):
            respuesta = responder_chatbot(pregunta)
        st.markdown(f"### üí¨ Respuesta:\n{respuesta}")
    else:
        st.warning("Por favor, escribe una consulta antes de enviar.")

st.markdown("---")
st.caption("üß† Basado en el hist√≥rico de consultas internas y el modelo GPT-4o de OpenAI.")
